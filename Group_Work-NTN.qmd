---
date: last-modified
bibliography: bio.bib
csl: harvard-cite-them-right.csl
title: Next To Normal's Group Project
execute:
  echo: false
  freeze: true
format:
  html:
    code-copy: true
    code-link: true
    toc: true
    toc-title: On this page
    toc-depth: 2
    toc_float:
      collapsed: false
      smooth_scroll: true
  pdf:
    include-in-header:
      text: |
        \addtokomafont{disposition}{\rmfamily}
    mainfont: Spectral
    sansfont: "Roboto Flex"
    monofont: "Liberation Mono"
    papersize: a4
    geometry:
      - top=25mm
      - left=40mm
      - right=30mm
      - bottom=25mm
      - heightrounded
    toc: false
    number-sections: false
    colorlinks: true
    highlight-style: github
jupyter:
  jupytext:
    text_representation:
      extension: .qmd
      format_name: quarto
      format_version: '1.0'
      jupytext_version: 1.15.2
  kernelspec:
    display_name: Python 3 (ipykernel)
    language: python
    name: python3
---

## Declaration of Authorship {.unnumbered .unlisted}

We, [Next To Normal], pledge our honour that the work presented in this assessment is our own. Where information has been derived from other sources, we confirm that this has been indicated in the work. Where a Large Language Model such as ChatGPT has been used we confirm that we have made its contribution to the final submission clear.

Date:15/12

Student Numbers: 25109433,25243075,25063842,25223683,25245242

## Priorities for Feedback

Are there any areas on which you would appreciate more detailed feedback if we're able to offer it?

{{< pagebreak >}}

**Remove this page (up to the next `pagebreak`) prior to submission!**

# Code Examples

This page has example code to show you can include outputs while hiding code in Quarto, as well as some tools for interpolating data in the text. 

See the raw file for examples of how to hide computational output as there is code hidden here.

```{python}
#| echo: True 
# This code will be shown, 
# but the next block will not
import os
import pandas as pd
```

```{python}
# This code is not shown because echo was
# set to False in the header. You should
# think carefully about whether you want
# or need to show any code to the reader
# in the PDf.
host = 'https://orca.casa.ucl.ac.uk'
path = '~jreades/data'
file = '20250615-London-listings.parquet'

if os.path.exists(file):
  df = pd.read_parquet(file)
else: 
  df = pd.read_parquet(f'{host}/{path}/{file}')
  df.to_parquet(file)
```

An inline citation example: As discussed on @insideairbnb, there are many...

A parenthetical citation example: There are many ways to research Airbnb [see, for example, @insideairbnb]... 

```{python}
#| output: asis
# This is one way to write dynamic text. 'As is' means
# it will interpret the result as regular Quarto markdown 
# so the below `print` statement becomes plain text with
# the size of the dataframe interpolated into the string.
# When Quarto is done running the Python code what's left
# is plain-text and that is then treated as a paragraph
# like it would be if you'd written it in Quarto.
print(f"One of way to embed output in the text looks like this: after cleaning, we were left with {df.shape[0]:,} rows of data.")
```

```{python}
# The other way is to ensure that your variables are *simple* 
# data types that Quarto can understand. So notice below that
# we just have a single, inline `{python} with the value of
# the row directly inserted into the sentence. his should also work, but is sometimes less predictably
# reliable.
row_count = f"{df.shape[0]:,}"
```
The other way is to interpolate it directly into the sentence like this (`{python} row_count `); however, I've found it less reliable and it really requires you to be careful about data types. So `{python} print(f"{df.shape[0]:,}") ` probably won't work and you'll just see some Python code instead.

And here's a nice little chart straight into the document!

```{python}
ax = df.host_listings_count.plot.hist(bins=50);
ax.set_xlim([0,500]);
```

{{< pagebreak >}}

# Briefing
## Executive Summary

**Main takeaway**  
（1–2 句话，总结：Airbnb 在伦敦是否“失控”，以及是否需要监管）

**Key findings**  
- Airbnb 活动在伦敦呈现明显的空间不均衡分布，专业房东高度集中于……
- 少数专业房东控制了不成比例数量的房源，显示出明显的商业化特征。
- 若实施该提案，受影响的物业主要集中在……
- 该政策在缓解住房压力方面具有潜在益处，但也可能带来……
- 从社会流动性的角度看，该政策可被重新叙述为……
（上面是ai写的，我们需要结合自己的结论写摘要）：要注意：不写方法不写代码不写“我们将分析”完全模仿报告的摘要风格

## Background

简要概述伦敦短期租赁当前的争议焦点。
阐述反对党提出的政策建议及其引发争议的原因。
之前写的背景：#需要改
Background 近期，市长社会流动性顾问因非法出租公有暂住房屋的丑闻，将伦敦住房短缺与财富不平等的尖锐矛盾推向公众视野。 反对党借机提出强硬提案，要求对短期租赁（Airbnb）的房东实施强制登记并提高市政税，声称要平衡被 Airbnb 破坏的租赁和酒店市场。

本简报旨在评估这一政治驱动提案的经济合理性、社会公平性及对市长竞选的潜在政治影响。 现有分析表明，Airbnb 的商业化运营正在系统性地加剧伦敦的住房不平等问题。 造成这一现象的核心原因在于： 1.商业化挤占住房： 平台上职业房东和非法房源的存在，挤占了私人长租和酒店业的生存空间，从而损害了私人租房者的利益，并间接推高了区域房价。 2.加速区域财富不平等： 租金和房价上涨加剧了房主与非房主之间的财富差距。同时，房租压力使得低收入家庭向外伦敦迁移，加速了区域贫困的郊区化趋势。 3.社区旅游化： 商业运营引入了负面外部性（如噪音和滋扰），拉低了社区生活质量，导致社区走向“旅游化”。

## Analytical Framework and Data


这个所有人写完之后我来综合


# Question
## Q1: Is Airbnb “out of control” in London?

**Short answer**  
（一句话交代：例如
Airbnb activity in London is highly concentrated among a small subset of hosts, particularly professional hosts operating entire-home listings.）

**Evidence:**  
- 列数据，简要阐述数据，是什么，数据为（number)，数据表示了什么。


**Interpretation**  
详细阐述These patterns suggest that Airbnb activity in London is better understood
as spatially concentrated rather than uniformly excessive.

```{python}
# 这里才写 Python
import pandas as pd
import geopandas as gpd

df = pd.read_csv("data/listings.csv")
df.head()
```

## Q2: How many professional landlords are there?

**Short answer:**  
London has a relatively small number of professional landlords, totalling 5,222. These landlords play a significant role in shaping concerns about Airbnb being “out of control” in the city.

**Evidence:**  

- London has a total of **5,222 professional hosts**, accounting for **9.4% of all Airbnb hosts**.
  Professional hosts are defined as those operating **two or more entire-home listings**, a conservative threshold commonly used in the Airbnb literature to capture sustained commercial activity rather than casual home-sharing (@sainaghi2021mom).

![Share of Professional Hosts Among All Hosts](https://raw.githubusercontent.com/Taoo2025/casa0013_fsds_finalwork/fddef7c18e555c3704d4330345c058536fb0d83b/Share%20of%20Professional%20Hosts%20Among%20All%20Hosts.png)


- Professional hosts are unevenly distributed across space and rental orientation:
  - **Inner-city long-term professional hosts:** 3,590  
  - **Inner-city short-term professional hosts:** 108  
  - **Outer-city long-term professional hosts:** 921  
  - **Outer-city short-term professional hosts:** 603  

![Composition of Professional Hosts by Location and Rental Orientation](https://raw.githubusercontent.com/Taoo2025/casa0013_fsds_finalwork/fddef7c18e555c3704d4330345c058536fb0d83b/Composition%20of%20Professional%20Hosts%20by%20Location%20and%20Rental%20Orientation.png)
**Definitions and Analytical Scope**

Following the Airbnb literature, professional hosts are commonly defined as hosts operating multiple listings, reflecting a shift from casual home-sharing towards commercial provision (@sainaghi2021mom). Building on this approach, this study adopts a more conservative operational definition by restricting professional hosts to those managing **two or more entire-home listings**. This refinement is particularly relevant in the context of housing inequality, as entire-home listings imply a full withdrawal of dwellings from residential use and are therefore more directly associated with pressures on the long-term housing market.

To account for heterogeneity within this group, professional hosts are further classified by **spatial location (Inner vs Outer London)** and **rental orientation (short-term vs long-term)**. The Inner–Outer London distinction follows established findings that housing pressure and wealth inequality in London are structurally organised along this divide (@travers2016housing, p. 17), and that intensive commercial activities tend to concentrate in highly connected urban cores (@arcaute2016cities). Consistent with this literature, the City of London is included as part of the inner-city core.

Rental orientation is distinguished using a **90-day threshold**, derived from London’s short-term letting regulatory framework rather than a universal academic definition. This policy-relevant boundary allows listings that are persistently withdrawn from residential use to be distinguished from more occasional forms of short-term letting, aligning the empirical classification with ongoing political and regulatory debates.

**Interpretation:**  
The grouping results indicate that professional hosts do not constitute a homogeneous group. Their behaviour in the housing market varies markedly in terms of both operating intensity and spatial distribution. In numerical terms, professional hosts remain a minority of all Airbnb hosts; in terms of housing resource use and operating intensity, they have become one of the most influential groups on the platform.

This suggests that debates over whether Airbnb is “out of control” should not be assessed solely on the basis of host counts, but should instead focus on how different types of professional hosts use housing. This finding provides essential context for evaluating the scope and potential impacts of the opposition’s proposal in the subsequent analysis.

#放到后面数据分析Q4去，The KDE and MSOA-level analyses presented here further reveal a pronounced concentration of professional hosts in Inner London, whereas their presence in Outer London is comparatively sparse. This spatial asymmetry indicates that the disruptive effects of Airbnb are likely to be unevenly distributed across the city. Consequently, policy proposals that apply uniform registration and taxation measures without accounting for inner–outer differences risk both economic inefficiency and unintended social inequity.

#放到后面数据分析Q4去，KDE and MSOA-level analyses further reveal that such high-intensity short-term rentals are spatially concentrated in Inner London. This evidence suggests that Airbnb’s disruptive effects are unevenly distributed and underscores the need for differentiated policy responses rather than uniform regulation.

```{python}
# Q2
df = pd.read_csv("https://github.com/Taoo2025/casa0013_fsds_finalwork/raw/refs/heads/main/data/listings.csv") 

# Check the data content and format
print(df.head())
print(df.shape)

# Unify the column names
df.columns = df.columns.str.lower()
key_columns = [
    "id",
    "host_id",
    "room_type",
    "availability_365",
    "maximum_nights",
    "neighbourhood_cleansed",
    "latitude",
    "longitude"
]
# Back up data to safeguard against contamination of the original data.
df_select = df[key_columns].copy()
# numeric coercion
df_select["availability_365"] = pd.to_numeric(
    df_select["availability_365"],
    errors="coerce"
)

df_select["maximum_nights"] = pd.to_numeric(
    df_select["maximum_nights"],
    errors="coerce"
)
# Select the required columns
df_clean = (
    df_select
    .dropna(subset=[
        "availability_365",
        "maximum_nights",
        "host_id",
        "room_type",
        "neighbourhood_cleansed",
        "latitude",
        "longitude"
    ])
    .reset_index(drop=True)
)
# Inspect the dataframe before and after cleaning
print(df_clean.head())
print("Before NA cleaning:", len(df_select))
print("After NA cleaning:", len(df_clean))
# Filter properties
## 1.Only entire properties are available
df_entire = df_clean[df_clean["room_type"] == "Entire home/apt"].copy()
print(df_entire.head())
## 2.Count the number of entire properties owned by each landlord
host_entire_counts = (
    df_entire
    .groupby("host_id")
    .size()
    .reset_index(name="n_entire_homes")
)

## 3.Professional landlords: ≥2 properties
professional_hosts = host_entire_counts[
    host_entire_counts["n_entire_homes"] >= 2
]
## 4.Return to the listing level
df_professional = df_entire.merge(
    professional_hosts[["host_id"]],
    on="host_id",
    how="inner"
)
# Review the results of property listings screening
print(df_professional.head())
# Count the total number of landlords specialising in statistics.
n_professional_hosts = professional_hosts.shape[0]
print("Number of professional hosts:", n_professional_hosts)
# Review the affected properties
entire_counts_by_host = (
    df_professional
    .groupby("host_id")
    .size()
)

total_entire_listings_professional = entire_counts_by_host.sum()

print("Total entire-home listings owned by professional hosts:",
      total_entire_listings_professional)
# Take a look at the average number of entire properties owned by each professional landlord.
avg_entire_per_professional = entire_counts_by_host.mean()

avg_entire_per_professional
# Take a look at the median number of entire properties owned by professional landlords.

median_entire_per_professional = entire_counts_by_host.median()

median_entire_per_professional
# Inspect the current dataframe
print(len(df_professional))
print(df_professional.head())
# Defining the Inner and Outer Cities
## First, examine how the existing data names the London boroughs.
df_professional["neighbourhood_cleansed"].unique()
## Select the inner city area
## Inner London is defined as a set of central boroughs, including the City of London, which constitutes the historic and functional core of London and is consistently classified as part of Inner London in official statistics.
inner_boroughs = [
    "Camden",
    "Hackney",
    "Islington",
    "Kensington and Chelsea",
    "Lambeth",
    "Southwark",
    "Tower Hamlets",
    "Westminster",
    "Hammersmith and Fulham",
    "Wandsworth",
    "Lewisham",
    "Haringey",
    "Newham",
    "City of London"
]
## Use `np.where()` to create a new column named `inner_city`
df_professional["inner_city"] = np.where(
    df_professional["neighbourhood_cleansed"].isin(inner_boroughs),
    "Inner London",
    "Outer London"
)
#Define short-term and long-term rental categories, with the threshold set at 90 days.
##Further grouping based on short-term versus long-term rentals, though uncertain whether to select the 'availability_365' column or the 'maximum_nights' column. Therefore, first examine the median and mode of these two columns to observe the distribution pattern.
###The median availability of 189 days indicates that more than half of professional listings are unavailable for at least 176 days per year, suggesting a substantial degree of functional withdrawal from the housing market.
###By contrast, the median and modal maximum night setting of 365 indicates that most professional hosts impose no effective upper limit on booking duration, reflecting platform rule configuration rather than realised rental behaviour.
###Maximum night settings are used to identify the intended market role of professional hosts, distinguishing listings designed as long-term or quasi-hotel assets. Availability-based measures are subsequently employed to assess the intensity of commercial operation and its potential social externalities.
median_availability = df_professional["availability_365"].median()
mode_availability = df_professional["availability_365"].mode()
median_min_nights = df_professional["maximum_nights"].median()
mode_min_nights = df_professional["maximum_nights"].mode()
print("Availability_365:")
print("  Median:", median_availability)
print("  Mode(s):", mode_availability.tolist())

print("\nmaximum_nights:")
print("  Median:", median_min_nights)
print("  Mode(s):", mode_min_nights.tolist())
##Availability_365:
  #Median: 189.0
  #Mode(s): [0]

##maximum_nights:
 #Median: 365.0
  #Mode(s): [365]
# Define rental_role
df_professional["rental_role"] = np.where(
    df_professional["maximum_nights"] > 90,
    "Long-term oriented",
    "Short-term oriented"
)

#Calculate days_unavailable，Often regarded as proxy for usage intensity
df_professional["days_unavailable"] = (
    365 - df_professional["availability_365"]
)
#Quickly verify whether the new column has been successfully created and confirm that the data appears reasonable.
print(df_professional.head())

#Grouping
host_level = (
    df_professional
    .groupby("host_id")
    .agg(
        n_listings=("id", "count"),

        # Classifying landlords into inner and outer districts (majority principle)
        share_inner_city=("inner_city", lambda x: (x == "Inner London").mean()),

        # Classify landlords using short and long groups (majority principle, based on maximum_nights)
        share_long_term_role=("rental_role", lambda x: (x == "Long-term oriented").mean()),

        # Operational intensity (descriptive, not used for classification)
        median_days_unavailable=("days_unavailable", "median"),
        mean_days_unavailable=("days_unavailable", "mean")
    )
    .reset_index()
)

# Generate dominant_location, determining the landlord's primary spatial activity area based on the majority of property listings.
host_level["dominant_location"] = np.where(
    host_level["share_inner_city"] >= 0.5,
    "Inner London",
    "Outer London"
)

#Generate dominant_rental_role，share_long_term_role indicates the proportion of properties under this landlord's name that are systemically classified as 'long-term rental-oriented'.
host_level["dominant_rental_role"] = np.where(
    host_level["share_long_term_role"] >= 0.5,
    "Long-term oriented",
    "Short-term oriented"
)
#“This classification reflects the dominant pattern rather than the full heterogeneity of individual portfolios.”

#Create a new column host_group in host_level (where each row represents one professional host), and initially assign all hosts the value "Unclassified".
host_level["host_group"] = "Unclassified"
#Use loc with conditional statements to assign hosts into four categories.
host_level.loc[
    (host_level["dominant_location"] == "Inner London") &
    (host_level["dominant_rental_role"] == "Short-term oriented"),
    "host_group"
] = "Inner-city short-term professional hosts"

host_level.loc[
    (host_level["dominant_location"] == "Inner London") &
    (host_level["dominant_rental_role"] == "Long-term oriented"),
    "host_group"
] = "Inner-city long-term professional hosts"

host_level.loc[
    (host_level["dominant_location"] == "Outer London") &
    (host_level["dominant_rental_role"] == "Short-term oriented"),
    "host_group"
] = "Outer-city short-term professional hosts"

host_level.loc[
    (host_level["dominant_location"] == "Outer London") &
    (host_level["dominant_rental_role"] == "Long-term oriented"),
    "host_group"
] = "Outer-city long-term professional hosts"
#View grouping results
host_level["host_group"].value_counts()
#View the proxy metric for 'actual operational intensity'.
host_level.groupby("host_group")[[
    "median_days_unavailable",
    "mean_days_unavailable"
]].describe()

#visualisation
##Check the number of specialist landlords in each group
group_counts = (
    host_level["host_group"]
    .value_counts()
    .sort_index()
)
group_counts
##The proportion of the four categories among professional landlords
group_share = group_counts / group_counts.sum() * 100
import matplotlib.pyplot as plt
soft_blues = [
    "#4C72B0",
    "#55A868",
    "#C44E52",
    "#8172B3"
]


plt.figure(figsize=(6, 6))

plt.pie(
    group_share,
    labels=group_share.index,
    autopct="%.1f%%",
    startangle=90,
    colors=soft_blues,
    textprops={"fontsize": 10}
)

plt.title(
    "Composition of Professional Hosts by Location and Rental Orientation",
    fontsize=12
)

plt.axis("equal")
## Save image
### Define the save path
output_dir = "plotsQ2"  
filename = "Composition of Professional Hosts by Location and Rental Orientation.png"

### Create the folder (if it does not exist)
if not os.path.exists(output_dir):
    os.makedirs(output_dir)

### Stitch together the complete path
file_path = os.path.join(output_dir, filename)

### Save image
plt.savefig(file_path, dpi=300, bbox_inches="tight")
print(f"The image has been saved to:{file_path}")
plt.show()

##The proportion of professional landlords among all landlords

total_hosts = df_clean["host_id"].nunique()
professional_hosts_count = host_level["host_id"].nunique()

host_type_counts = pd.Series(
    {
        "Professional hosts": professional_hosts_count,
        "Non-professional hosts": total_hosts - professional_hosts_count
    }
)
host_type_counts
### Drawing
colors_simple = ["#4C72B0", "#DDDDDD"]

plt.figure(figsize=(5, 5))

plt.pie(
    host_type_counts,
    labels=host_type_counts.index,
    autopct="%.1f%%",
    startangle=90,
    colors=colors_simple,
    textprops={"fontsize": 10}
)

plt.title(
    "Share of Professional Hosts Among All Hosts",
    fontsize=12
)

plt.axis("equal")

### Define the save path
output_dir = "plotsQ2" 
filename = "Share of Professional Hosts Among All Hosts.png"

### Create the folder (if it does not exist)
if not os.path.exists(output_dir):
    os.makedirs(output_dir)

### Stitch together the complete path
file_path = os.path.join(output_dir, filename)

### Save image
plt.savefig(file_path, dpi=300, bbox_inches="tight")
print(f"Image saved to:{file_path}")
plt.show()
```
## Q3: How many properties would be affected by the proposal?

**Short answer:**  
（一句话说明影响规模）

**Evidence:**  
- 数据1
- 数据2
- 数据3

**Interpretation:**  


```{python}
# 这里才写 Python
import pandas as pd
import geopandas as gpd

df = pd.read_csv("data/listings.csv")
df.head()
```

## Q4: What are the likely pros and cons of the proposal?

### Implications for the Mayor
**Potential benefits:**  
- 
-

**Potential drawbacks:**  
- 
- 

### Implications for Residents
**Potential benefits:**  
- 
-

**Potential drawbacks:**  
- 
- 

### Implications for the City
**Potential benefits:**  
- 
-

**Potential drawbacks:**  
- 
- 

### Spatial Evidence: High Leverage vs Uneven Costs
**Key Spatial Patterns** 

**Interpretation** 

```{python}
# 这里才写 Python
import pandas as pd
import geopandas as gpd

df = pd.read_csv("data/listings.csv")
df.head()
```
## Q5: Can the story be reframed positively in terms of social mobility?
（我觉得这一问的内容结构取决于写这个的同学）
**Short answer:**  
（一句话总结）

**Evidence and framing:**  
- 1
- 2
- 3
**Interpretation** 
Policy Implications and Recommendations



```{python}
# 这里才写 Python
import pandas as pd
import geopandas as gpd

df = pd.read_csv("data/listings.csv")
df.head()
```

## Overall Assessment

## Transparency and Limitations
（这些是Q2/4的，自己加自己负责的部分的Transparency and Limitations）
- This analysis relies on scraped platform data and operational definitions of professional landlords, which may under- or over-estimate true levels of commercial activity. Spatial patterns should therefore be interpreted as indicative rather than definitive.
- Operating nights are proxied using availability data.
- The 90-day threshold is policy-relevant but imperfect.
- Results describe relative patterns rather than causal effects.


{{< include _questions.qmd >}}

## References
把自己用到的文献都放进来，注意老师说的参考文献的方式！！！！
'在 Quarto 中，您需要使用 BibTeX 和 Markdown格式进行引用。“硬编码”的引用将不被接受。'





